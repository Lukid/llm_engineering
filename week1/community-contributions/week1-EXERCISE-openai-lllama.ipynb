{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import ollama\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "system = \"\"\"\n",
    "You are an intelligent assistant designed to provide clear and concise answers to user questions. \n",
    "Your responses must be direct, to the point, and free from unnecessary elaboration or jargon. \n",
    "For every answer, first provide the response in English, followed by a version in Italian. \n",
    "Ensure that both versions are accurate, consistent, and convey the same meaning. \n",
    "If a question is ambiguous or lacks sufficient detail, politely ask for clarification before proceeding. \n",
    "Maintain a neutral and professional tone at all times.\n",
    "\"\"\"\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d15896a-0752-4f82-9494-f01b006170fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain transformers in LLM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5e6ae57-977a-4aea-ae0f-48dc507172f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system},\n",
    "    {\"role\": \"user\", \"content\": question},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "openai = OpenAI()\n",
    "def get_openai_answer():\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8b07cce-9e99-42fe-a816-297d6cc89e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Transformers are a type of model architecture widely used in large language models (LLMs). They utilize self-attention mechanisms to process and generate text, allowing them to consider the context of each word in relation to others in a sequence. This enables the model to capture long-range dependencies and improve comprehension and generation of language.\n",
       "\n",
       "I trasformatori sono un tipo di architettura di modello ampiamente utilizzata nei grandi modelli di linguaggio (LLM). Utilizzano meccanismi di autoattenzione per elaborare e generare testo, consentendo loro di considerare il contesto di ciascuna parola in relazione ad altre in una sequenza. Questo consente al modello di catturare dipendenze a lungo raggio e migliorare la comprensione e la generazione del linguaggio."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_openai_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "def get_llama_answer():\n",
    "    stream = ollama.chat(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages = messages,\n",
    "        stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.message.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "726d3903-80d7-4134-b211-62d92ac78dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**English**\n",
       "Transformers are a type of neural network architecture used in Natural Language Processing (NLP) tasks, particularly in Large Language Models (LLMs). They process sequential data, such as text, by dividing it into smaller segments called \"tokens\" and applying self-attention mechanisms to relationships between these tokens.\n",
       "\n",
       "The transformer architecture consists of an encoder and a decoder. The encoder takes in a sequence of tokens and outputs a fixed-length vector representation of the input sequence. The decoder then generates a sequence of tokens based on this output, one token at a time.\n",
       "\n",
       "Transformers have been shown to be highly effective in various NLP tasks, including language translation, text summarization, and question-answering.\n",
       "\n",
       "**Italian**\n",
       "I transformatori sono un tipo di archittettura di rete neurale utilizzata nei compiti di Processamento del Linguaggio Naturale (NLP), in particolare nelle modelle linguistiche grandi (LLM). \n",
       "Processano dati sequenziali, come il testo, dividendoli in segmenti pi√π piccoli chiamati \"token\" e applicando meccanismi di attenzione autosemplice ai rapporti tra questi token.\n",
       "\n",
       "L'architettura dei transformatori consiste in un encoder ed un decoder. L'encoder prende in input una sequenza di token e produce una rappresentazione a lunghezza fissa del sequence d'input. Il decoder poi genera una sequenza di token in base all'output precedente, uno token alla volta.\n",
       "\n",
       "I transformatori hanno dimostrato essere estremamente efficaci in vari compiti NLP, come la traduzione linguistica, la sommazione dei testi e la risposta alle domande."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_llama_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0951ba-4691-4d08-b37b-3f41e75e05cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
